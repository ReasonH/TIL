## 카프카 클러스터

### 브로커
- 카프카 클라이언트와 데이터를 주고받는 주체
- 하나의 서버에 하나의 브로커 프로세스 실행
- 프로듀서가 보낸 데이터를 분산 저장

### 클러스터
- 데이터 처리 및 안정성을 위해 여러 브로커를 묶어서 운영

### 주키퍼
- 카프카 클러스터 실행을 위해 필요 (3.0 부터는 주키퍼 없이 동작 가능)

### 브로커 역할 상세
- 컨트롤러: 여러 브로커 중 한 대가 수행하는 역할, 다른 브로커 상태 체크 -> 문제 시 리더 재분배
- 데이터 삭제: 데이터는 소비되어도 사라지지 않으며 브로커만이 세그먼트 단위로 삭제 가능
- 컨슈머 오프셋 저장: 컨슈머 그룹이 소비한 메시지에 대해 오프셋 저장
- 그룹 코디네이터: 컨슈머 그룹 상태 체크, 파티션이 컨슈머와 항상 매칭되도록 리밸런싱

### 로그 세그먼트
데이터는 브로커를 통해 세그먼트 단위로 정리된다.

#### 세그먼트
브로커는 데이터를 저장한다. 이 때 메시지와 메타데이터는 .log 파일로 저장된다.
로그는 하나의 파일이 아닌 여러 작은 파일로 나뉘는데, 이를 세그먼트라고 한다.
세그먼트의 첫 번째 레코드 offset이 세그먼트 파일명이 된다.

- log.segment.bytes: 바이트 단위 최대 세그먼트 크기
- log.roll.ms(hours): 세그먼트 생성 이후 다음 파일로 넘어가는 시간
둘 중 먼저 도달하는 기준에 따라 세그먼트가 나뉜다.

#### 액티브 세그먼트
쓰기가 일어나고 있는 세그먼트로 브로커의 삭제 대상에 포함되지 않는다.

#### 세그먼트와 삭제 주기
- retention.ms(bytes): 시간, 용량 기준으로 삭제 주기 설정 가능
- log.retention.check.interval.ms: 세그먼트 삭제 여부를 판단하는 인터벌 설정
- active가 아닌 세그먼트들만 삭제

#### 세그먼트 삭제
- 카프카는 세그먼트 단위로 데이터를 제거하기 때문에 레코드 단위로는 삭제가 불가능
- 수정 또한 불가능하기 때문에 p 또는 c에서 데이터 검증이 필요

#### 세그먼트 압축
- 메시지 키 별, 해당 키의 레코드 중 오래된 데이터를 삭제
- 삭제와 다르게 일부 레코드만 제거 가능
- active가 아닌 세그먼트에서만 압축
K-V 스토어 처럼 활용할 때는 유용하다.

##### 테일 영역
압축이 완료된 레코드, 클린 로그, 중복 메시지 키 없음
##### 헤드 영역
압축 전 레코드, 더티 로그, 중복 메시지 키 있음
- 이 비율을 통해 압축이 얼마나 발생할 것인지 조정할 수 있다.

### 데이터 복제
- 브로커 문제 발생 시 데이터 복원을 위한 정책, 파티션 단위로 복제가 이루어진다.
- p / c와 직접 통신은 리더 파티션만 한다. 팔로워 파티션은 이를 따라간다.
- 유실 허용 여부에 따라 replica 수를 결정한다. (최소값은 1이며 복제 없음이다.)

#### ISR
리더 파티션 데이터가 팔로워에 완전히 동기화된 상태를 뜻한다.
리더 파티션 데이터를 팔로워가 모두 복제하지 못한 상태에서 리더로 선출되면 데이터가 유실될 수 있다. 유실을 감수한다면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정 가능하다.
- unclean.leader.election.enable=true : 유실 감수
- unclean.leader.election.enable=false : 유실을 허용하지 않음, 해당 브로커 복구까지 중단

### 토픽과 파티션
토픽은 데이터 구분을 위한 단위이며 하나 이상의 파티션을 소유한다. 토픽의 데이터(레코드)는 다양한 컨슈머가 여러번 가져갈 수 있다.
- 파티션은 라운드로빈 방식으로 생성되기 때문에 핫스팟을 방지하고, 선형 확장이 가능하다.
- 특정 브로커에 파티션이 쏠리는 경우, 파티션을 재분배가 필요 (기본적으로 sh 파일 포함되어 있다.)

#### 파티션, 컨슈머, 처리량
**그룹으로 묶인** 컨슈머들이 레코드를 병렬로 처리하기 위해서는 파티션의 갯수도 늘려야 한다. 컨슈머만 늘려도 동일한 파티션이 여러 컨슈머에 할당될 수 없기 때문에 컨슈머와 파티션을 같이 늘려야 한다.
> 아마 컨슈머 별로 offset을 관리하고 이게 공유되지 않기 때문일 것 같다.

! 파티션 개수를 줄이는 것은 지원하지 않는다. 한 번 늘린 파티션을 줄이기 위해서는 토픽을 재생성하는 방법밖에 없다. 따라서 신중하게 작업해야 한다.

### 레코드
레코드 구성요소는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋이다.

##### 타임스탬프
- Unix Timestamp
- 레코드 생성 시간, 브로커 적재 시간 등으로 설정 가능
- 토픽 단위 설정 가능
##### 오프셋
- 각 메시지는 파티션 별 고유 오프셋을 갖는다.
- 컨슈머는 이를 이용해 처리한 데이터와 처리할 데이터를 구분하고, 중복 처리를 방지
- 브로커 적재 시점에 생성
##### 헤더
- 프로세싱 참고할 정보
##### 메시지 키
- 처리할 메시지 값에 대한 분류 용도 (파티셔닝)
- 메시지 키가 있는 경우 파티셔너에 따라 파티션 번호가 정해진다.
	- ex) 해싱을 쓰는 경우 키가 같으면 계속 동일한 파티션에 전달
- 메시지 키가 없는 경우 라운드로빈 방식으로 매핑
##### 메시지 값
- 실제 처리할 데이터, 다양한 형태 지원

### 토픽 이름
- 영어 대, 소문자, 숫자, 마침표, 언더바, 하이폰 조합 가능 -> 마침표와 언더바는 동시 사용 지양
- 내부 예약 토픽명 불가능

### 클라이언트 메타데이터
카프카 클라이언트는 통신하고자 하는 리더 파티션 위치를 알기 위해 브로커로부터 메타데이터를 전달받는다.
- metadata.max.age.ms / metadata.max.idle.ms 옵션을 통해 메타데이터 리프레시를 조절할 수 있다.

잘못된 브로커로 데이터를 요청하는 경우 LEADER_NOT_AVAILABLE 예외가 발생한다. 이 경우 메타데이터 만료 이슈인 경우기 많기 때문에 refresh 간격을 조정한다.

---